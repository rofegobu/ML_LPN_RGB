{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disponibilización de modelos\n",
    "\n",
    "En este notebook aprenderá a guardar un modelo y a disponibilizarlo como una API con la librería Flask. Una API (interfaz de programación de aplicaciones) es un conjunto de definiciones y protocolos que permiten que servicios, en este caso modelos, retornen resultados y respuestas sin necesidad de saber cómo están implementados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrucciones Generales:\n",
    "\n",
    "Este notebook esta compuesto por dos secciones. En la primera sección, se entrena y guarda (exportar) un modelo de XGBoost con Calibración para predecir el precio de un automóvil. En la segunda parte, se usa el modelo entrenado y se disponibiliza usando la libreria *Flask*. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar base de datos y librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import joblib\n",
    "#import os\n",
    "#os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de archivos .csv\n",
    "dataTraining = pd.read_csv('https://raw.githubusercontent.com/rofegobu/ML_LPN_RGB/main/dataTrain_carListings.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificar y Eliminar Valores Atípicos (Outliers) - Filtrado 1 y 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identificar y Eliminar Valores Atípicos (Outliers) - Filtrado 1\n",
    "\n",
    "# Identificar y eliminar valores atípicos de 'Price' y 'Milage' para cada 'Model' y 'Year',\n",
    "\n",
    "# Agrupar por 'Year' y 'Model' y calcular la media y la desviación estándar para 'Price' y 'Mileage'\n",
    "grouped = dataTraining.groupby(['Year', 'Model']).agg({\n",
    "    'Price': ['mean', 'std'],\n",
    "    'Mileage': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "# Aplanar encabezado de las columnas multi-índice\n",
    "grouped.columns = ['Year', 'Model', 'Price_mean', 'Price_std', 'Mileage_mean', 'Mileage_std']\n",
    "\n",
    "# Unir los cálculos anteriores al DataFrame original para tener los valores de referencia por año y modelo\n",
    "dataTraining = dataTraining.merge(grouped, on=['Year', 'Model'], how='left')\n",
    "\n",
    "# Identificar valores atípicos usando la media y la desviación estándar por año y modelo\n",
    "outliers = dataTraining[\n",
    "    ((dataTraining['Price'] < (dataTraining['Price_mean'] - 1.5 * dataTraining['Price_std'])) |\n",
    "     (dataTraining['Price'] > (dataTraining['Price_mean'] + 1.5 * dataTraining['Price_std']))) |\n",
    "    ((dataTraining['Mileage'] < (dataTraining['Mileage_mean'] - 1.5 * dataTraining['Mileage_std'])) |\n",
    "     (dataTraining['Mileage'] > (dataTraining['Mileage_mean'] + 1.5 * dataTraining['Mileage_std'])))\n",
    "]\n",
    "\n",
    "# Eliminar filas con valores atípicos\n",
    "dataTraining_filtrado1 = dataTraining.drop(outliers.index)\n",
    "\n",
    "# Eliminar columnas auxiliares usadas para los cálculos\n",
    "dataTraining_filtrado1 = dataTraining_filtrado1.drop(columns=['Price_mean', 'Price_std', 'Mileage_mean', 'Mileage_std'])\n",
    "\n",
    "# Mostrar DataFrame actualizado\n",
    "#print(dataTraining_filtrado1)\n",
    "\n",
    "\n",
    "## Identificar y Eliminar Valores Atípicos (Outliers) - Filtrado 2\n",
    "\n",
    "# Identificar y eliminar valores atípicos de 'Price' para cada 'Model', 'Year' y 'Mileage_range'\n",
    "\n",
    "# Crear la columna 'Mileage_range'\n",
    "dataTraining_filtrado1['Mileage_range'] = (np.ceil(dataTraining_filtrado1['Mileage'] / 5000) * 5000).astype(int)\n",
    "\n",
    "# Agrupar por 'Year', 'Model', y 'Mileage_range' y calcular la media y la desviación estándar para 'Price'\n",
    "grouped = dataTraining_filtrado1.groupby(['Year', 'Model', 'Mileage_range']).agg({\n",
    "    'Price': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "# Aplanar encabezado de las columnas multi-índice\n",
    "grouped.columns = ['Year', 'Model', 'Mileage_range', 'Price_mean', 'Price_std']\n",
    "\n",
    "# Unir los cálculos anteriores al DataFrame original para tener los valores de referencia\n",
    "dataTraining_filtrado1 = dataTraining_filtrado1.merge(grouped, on=['Year', 'Model', 'Mileage_range'], how='left')\n",
    "\n",
    "# Identificar los valores atípicos usando la media y la desviación estándar para 'Price'\n",
    "outliers = dataTraining_filtrado1[\n",
    "    ((dataTraining_filtrado1['Price'] < (dataTraining_filtrado1['Price_mean'] - 1.5 * dataTraining_filtrado1['Price_std'])) |\n",
    "     (dataTraining_filtrado1['Price'] > (dataTraining_filtrado1['Price_mean'] + 1.5 * dataTraining_filtrado1['Price_std'])))\n",
    "]\n",
    "\n",
    "# Eliminar filas con valores atípicos\n",
    "dataTraining_filtrado2 = dataTraining_filtrado1.drop(outliers.index)\n",
    "\n",
    "# Eliminar columnas auxiliares usadas para los cálculos\n",
    "dataTraining_filtrado2 = dataTraining_filtrado2.drop(columns=['Price_mean', 'Price_std', 'Mileage_range'])\n",
    "\n",
    "# Mostrar DataFrame actualizado\n",
    "#print(dataTraining_filtrado2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer valores únicos de las columnas State Make y Model\n",
    "states = dataTraining['State'].unique().tolist()\n",
    "makes = dataTraining['Make'].unique().tolist()\n",
    "models = dataTraining['Model'].unique().tolist()\n",
    "\n",
    "# Escribir los valores únicos a un archivo .py dentro del directorio 'content'\n",
    "with open('content/unique_values.py', 'w') as file:\n",
    "    file.write(\"STATES = \" + str(states) + \"\\n\")\n",
    "    file.write(\"MAKES = \" + str(makes) + \"\\n\")\n",
    "    file.write(\"MODELS = \" + str(models) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación de características numéricas y categóricas - Pipeline de preprocesamiento - División de los datos en conjuntos de entrenamiento y validación "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transformación de características numéricas y categóricas - Pipeline de preprocesamiento - División de los datos en conjuntos de entrenamiento y validación \n",
    "\n",
    "\n",
    "# Selección de características\n",
    "numeric_features = ['Year', 'Mileage']\n",
    "categorical_features = ['State', 'Make', 'Model']\n",
    "\n",
    "# Pipeline para características numéricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Pipeline para características categóricas\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "# Combinar transformadores en un preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "y = dataTraining_filtrado2['Price']\n",
    "X = dataTraining_filtrado2.drop('Price', axis=1)\n",
    "\n",
    "# División en conjuntos de entrenamiento y validación\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Aplicar el preprocesador\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_valid_preprocessed = preprocessor.transform(X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content/preprocessor.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exportar el preprocesador entrenado\n",
    "joblib.dump(preprocessor, 'content/preprocessor.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar y guardar modelo XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE XGBoost post-calibración en conjunto de validación: 2225.45\n"
     ]
    }
   ],
   "source": [
    "## Entrenar y guardar modelo XGBoost\n",
    "\n",
    "# Configurar modelo XGBoost con los mejores parámetros encontrados\n",
    "xgb_model = XGBRegressor(\n",
    "    colsample_bytree=0.925,\n",
    "    gamma=0.936,\n",
    "    learning_rate=0.246,\n",
    "    max_depth=10,\n",
    "    n_estimators=439,\n",
    "    subsample=0.790,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar modelo con datos de entrenamiento preprocesados\n",
    "xgb_model.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Predicir en el conjunto de validación\n",
    "y_pred = xgb_model.predict(X_valid_preprocessed)\n",
    "\n",
    "# Calcular RMSE para el conjunto de validación\n",
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "print(f\"RMSE XGBoost post-calibración en conjunto de validación: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['content/price_predictor_xgb.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exportar modelo de regresión a archivo binario .pkl\n",
    "joblib.dump(xgb_model, 'content/price_predictor_xgb.pkl', compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disponibilizar modelo con Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (fsevents)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/robertogb/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py\", line 15, in <module>\n",
      "    from ipykernel import kernelapp as app\n",
      "  File \"/Users/robertogb/anaconda3/lib/python3.11/site-packages/ipykernel/__init__.py\", line 5, in <module>\n",
      "    from .connect import *  # noqa\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robertogb/anaconda3/lib/python3.11/site-packages/ipykernel/connect.py\", line 11, in <module>\n",
      "    import jupyter_client\n",
      "  File \"/Users/robertogb/anaconda3/lib/python3.11/site-packages/jupyter_client/__init__.py\", line 8, in <module>\n",
      "    from .asynchronous import AsyncKernelClient  # noqa\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robertogb/anaconda3/lib/python3.11/site-packages/jupyter_client/asynchronous/__init__.py\", line 1, in <module>\n",
      "    from .client import AsyncKernelClient  # noqa\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/robertogb/anaconda3/lib/python3.11/site-packages/jupyter_client/asynchronous/client.py\", line 8, in <module>\n",
      "    from jupyter_client.client import KernelClient\n",
      "  File \"/Users/robertogb/anaconda3/lib/python3.11/site-packages/jupyter_client/client.py\", line 22, in <module>\n",
      "    from .connect import ConnectionFileMixin\n",
      "  File \"/Users/robertogb/anaconda3/lib/python3.11/site-packages/jupyter_client/connect.py\", line 27, in <module>\n",
      "    from jupyter_core.paths import jupyter_data_dir\n",
      "  File \"/Users/robertogb/anaconda3/lib/python3.11/site-packages/jupyter_core/paths.py\", line 19, in <module>\n",
      "    from pathlib import Path\n",
      "  File \"/Users/robertogb/anaconda3/lib/python3.11/site-packages/pathlib.py\", line 10, in <module>\n",
      "    from collections import Sequence\n",
      "ImportError: cannot import name 'Sequence' from 'collections' (/Users/robertogb/anaconda3/lib/python3.11/collections/__init__.py)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "## Disponibilizar modelo con Flask\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_restx import Api, Resource, fields\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from content.unique_values import STATES, MAKES, MODELS\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "api = Api(\n",
    "    app, \n",
    "    version='1.0', \n",
    "    title='API de Predicción de Precios - Automóviles usados',\n",
    "    description='API para predecir precios de automóviles usados en EE.UU.')\n",
    "\n",
    "\n",
    "# Espacio de nombres para la API\n",
    "ns = api.namespace('predict', description='Predicciones')\n",
    "\n",
    "\n",
    "# Modelo de datos de entrada de la API\n",
    "model = api.model('PredictionInput', {\n",
    "    'Year': fields.Integer(required=True, description='Año del vehículo', example=2016),\n",
    "    'Mileage': fields.Float(required=True, description='Kilometraje del vehículo', example=50000),\n",
    "    'State': fields.String(required=True, description='Estado donde se encuentra el vehículo', enum=STATES),\n",
    "    'Make': fields.String(required=True, description='Marca del vehículo', enum=MAKES),\n",
    "    'Model': fields.String(required=True, description='Modelo del vehículo', enum=MODELS)\n",
    "})\n",
    "\n",
    "# Cargar el modelo y preprocesador entrenados\n",
    "model_auto_price = joblib.load('content/price_predictor_xgb.pkl')\n",
    "preprocessor = joblib.load('content/preprocessor.pkl')\n",
    "\n",
    "# Ruta del recurso de predicción   \n",
    "@ns.route('/')\n",
    "class Predict(Resource):\n",
    "    @api.expect(model)\n",
    "    def post(self):\n",
    "        data = request.json\n",
    "        input_df = pd.DataFrame([data])\n",
    "        preprocessed_data = preprocessor.transform(input_df)\n",
    "        prediction = model_auto_price.predict(preprocessed_data)\n",
    "        # Convert numpy float32 to Python float\n",
    "        prediction = float(prediction[0])\n",
    "        return jsonify({'predicted_price': prediction})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5001\n",
      " * Running on http://192.168.1.100:5001\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [27/Apr/2024 19:42:02] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2024 19:42:02] \"GET /swaggerui/swagger-ui.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [27/Apr/2024 19:42:02] \"GET /swaggerui/droid-sans.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [27/Apr/2024 19:42:02] \"GET /swaggerui/swagger-ui-standalone-preset.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [27/Apr/2024 19:42:02] \"GET /swaggerui/swagger-ui-bundle.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [27/Apr/2024 19:42:03] \"GET /swagger.json HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:10:30] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:10:30] \"GET /swaggerui/droid-sans.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:10:30] \"GET /swaggerui/swagger-ui.css HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:10:30] \"GET /swaggerui/swagger-ui-standalone-preset.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:10:30] \"GET /swaggerui/swagger-ui-bundle.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:10:30] \"GET /swagger.json HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:10:46] \"POST /predict/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:10:48] \"POST /predict/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:11:06] \"POST /predict/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:11:16] \"POST /predict/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:11:28] \"POST /predict/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:11:45] \"POST /predict/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:11:53] \"POST /predict/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:12:04] \"POST /predict/ HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [27/Apr/2024 20:12:09] \"POST /predict/ HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Ejecución de la aplicación que disponibiliza el modelo de manera local en el puerto 5000\n",
    "app.run(debug=True, use_reloader=False, host='0.0.0.0', port=5001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo debe haber quedado disponibilizado en el puerto 5000. Para predecir la probabilidad de que una URL sea fraudulenta (phishing) copie en la barra de busqueda de su navegador la siguiente dirección (http://localhost:5000/predict/?URL=) y agregregue al final de esta la URL que desee precir. Por ejemplo, al copiar la URL http://localhost:5000/predict/?URL=http://consultoriojuridico.co/pp/www.paypal.com/, la API retornará la probabilidad de que la URL http://consultoriojuridico.co/pp/www.paypal.com/ sea phishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
